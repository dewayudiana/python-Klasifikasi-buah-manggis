from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import matplotlib.pyplot as plt

import keras 
keras.__version__

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(zoom_range=0.1, shear_range=0.1, horizontal_flip=True, validation_split=0.2)

from google.colab import drive
drive.mount('/content/drive')

training_set = datagen.flow_from_directory(directory='/content/drive/My Drive/cnn/dataset2', 
                                           target_size=(200, 200), 
                                           batch_size=32, 
                                           class_mode='categorical', 
                                           subset='training')
validation_set = datagen.flow_from_directory(directory='/content/drive/My Drive/cnn/dataset2', 
                                           target_size=(200, 200), 
                                           batch_size=32, 
                                           class_mode='categorical', 
                                           subset='validation')
                                           
num_train_steps = len(training_set.filenames) // 32
num_valid_steps = len(validation_set.filenames) // 32

print(num_train_steps)
print(num_valid_steps)

model = Sequential()

model.add(Conv2D(32, (3, 3), input_shape=(200, 200, 3), activation='relu'))
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(7, activation='softmax'))

from keras.optimizers import Adam

model.compile(loss="categorical_crossentropy",
              optimizer=Adam(lr=0.001),
              metrics=["accuracy"])
           
hist = model.fit_generator(training_set,
                         steps_per_epoch=num_train_steps, 
                         validation_data=validation_set, 
                         validation_steps=num_valid_steps, 
                         epochs=40)
model.save('/content/drive/My Drive/cnn/percobaan_epoch40.h5')

# trained_model.summary()
train_loss=hist.history['loss']
val_loss=hist.history['val_loss']
train_acc=hist.history['acc']
val_acc=hist.history['val_acc']
xc=range(60)

plt.figure(1,figsize=(20,10), dpi=100)
plt.plot(xc,train_loss)
plt.plot(xc,val_loss)
plt.xlabel('num of Epochs')
plt.ylabel('loss')
plt.title('train_loss vs val_loss')
plt.grid(True)
# plt.legend(['train','val'])
plt.style.use(['classic'])
plt.savefig('train_loss vs val_loss data Val 30%.png')

plt.figure(2,figsize=(20,10), dpi=100)
plt.plot(xc,train_acc)
plt.plot(xc,val_acc)
plt.xlabel('num of Epochs')
plt.ylabel('accuracy')
plt.title('train_acc vs val_acc')
plt.grid(True)
# plt.legend(['train','val'])
plt.style.use(['classic'])
plt.savefig('train_acc vs val_acc data Val 30%.png')

from keras.models import load_model

trained_model = load_model('model_manggis_adamNewData.h5')

trained_model.to_json()

import numpy as np
from keras.preprocessing import image
import math

img_path = '/content/drive/My Drive/cnn/ywudjewr.png'
img = image.load_img(img_path, target_size=(200, 200))
test_image = image.img_to_array(img)
test_image = np.expand_dims(test_image, axis = 0)
result = trained_model.predict(test_image)
classes = list(training_set.class_indices)
hasil = ''
for i in range(len(classes)):
    hasil += str(classes[i]) + ' : ' + str(math.floor(result[0][i] * 100)) + '%' + '\n'
#     hasil += str(classes[i]) + ' : ' + str(result[0][i]) + '\n'
print(hasil)

